{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandit Line Walk\n",
    "\n",
    "In this notebook, we test our knowledge of multi-armed bandits on the a line wark problem. Th\n",
    "e formulation of a line walk problem is as follows:\n",
    "- We have a line scaled from 0 to $\\texttt{max\\_scale}$.\n",
    "- We set sample random two variables $\\texttt{agent\\_position}$ and $\\texttt{goal}$ in the line scale. These are:\n",
    "    - $\\texttt{agent\\_position}$: our agent position\n",
    "    - $\\texttt{goal}$: our goal position\n",
    "- We can perfom n set actions action which basically determines how the agent towards to the goal.\n",
    "- Objective: Find the set of actions to makes the agent reach the goal.\n",
    "- Can your agent find the least number of steps?\n",
    "\n",
    "\n",
    "Note: This is a search problem and this can easily be solved used binary search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n",
    "\n",
    "We start by creating the environment which is a fairly simple one.\n",
    "- We generate the goal and the agent position\n",
    "- Our reward at a given time step is given by:\n",
    "\n",
    "$$ R_t = \\begin{cases} \n",
    "      \\frac{1}{|\\texttt{agent\\_positon}_t - \\texttt{goal}| + 1} & 0 \\leq x \\leq \\texttt{max\\_scale} \\\\\n",
    "      -1 & otherwise\n",
    "   \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineWalkEnvironment:\n",
    "    def __init__(self, max_scale, allowed_steps) -> None:\n",
    "        self.max_scale = max_scale\n",
    "        self.goal = np.random.randint(0, self.max_scale)\n",
    "        self.agent_position = self.get_new_agent_position(self.max_scale, self.goal)\n",
    "        self.allowed_stpes = allowed_steps\n",
    "        \n",
    "    def get_new_agent_position(self, max_scale, goal):\n",
    "        # sample the position of the agent while \n",
    "        # excluding the goal position\n",
    "        tmp = list(range(max_scale)).remove(goal)\n",
    "        return np.random.choice(tmp)\n",
    "    \n",
    "    def reset_agent_position(self):\n",
    "        self.agent_position = self.get_new_agent_position(self.max_scale, self.goal)\n",
    "        \n",
    "    def walk(self, step):\n",
    "        assert step in self.allowed_stpes\n",
    "        self.agent_position += step\n",
    "        \n",
    "        if self.agent_position in list(range(self.max_scale)):\n",
    "            return 1 / (np.abs(self.goal - self.agent_position) + 1)\n",
    "        else:\n",
    "            return -1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the agent\n",
    "\n",
    "- The only information our greedy agent has is:\n",
    "    - The set of actions it can perform.\n",
    "    - The expected gain of each action along over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyWalker:\n",
    "    def __init__(self, allowed_steps) -> None:\n",
    "        assert isinstance(allowed_steps, list) and len(allowed_steps) > 1\n",
    "        self.allowed_steps = allowed_steps\n",
    "        self.expected_gain = [1 for _ in range(len(self.allowed_steps))]\n",
    "        \n",
    "    def walk(self, environment):\n",
    "        step_idx = np.random.choice(np.arange(len(self.allowed_steps)), p=self.expected_gain)\n",
    "        reward = environment.walk(self.allowed_steps[step_idx]) + np.random.normal()\n",
    "        \n",
    "        # update the cumulative reward of our agent\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('rl-lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3966e3b9d6dc55552b8230db0eeabe240b857644b120091101d8a1684aa2afe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
